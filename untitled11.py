# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TUXRUVXg7Jc2gv2qN1cocdqwWzk4HkFx
"""

# STEP 1: Install required packages
!pip install onnx onnxruntime torch torchvision tensorflow

# STEP 2: Upload ONNX model
from google.colab import files
uploaded = files.upload()  # Upload your model.onnx

# STEP 3: Load ONNX and test it
import onnxruntime as ort
import numpy as np

# Get input/output names and dummy input
session = ort.InferenceSession("model.onnx")
input_name = session.get_inputs()[0].name
output_name = session.get_outputs()[0].name
input_shape = session.get_inputs()[0].shape
print(f"Input name: {input_name}, shape: {input_shape}")
print(f"Output name: {output_name}")

# STEP 4: Create dummy TensorFlow model to match ONNX behavior
import tensorflow as tf
from tensorflow.keras import layers

# You must edit this manually to match your architecture
model = tf.keras.Sequential([
    layers.Input(shape=(3, 32, 32)),  # Edit as per your ONNX model
    layers.Permute((2, 3, 1)),  # Convert from NCHW â†’ NHWC
    layers.Conv2D(16, 3, activation='relu'),
    layers.Flatten(),
    layers.Dense(10, activation='softmax')  # Change output units as needed
])
model.summary()
# Use model.export() to create a SavedModel directory
model.export("saved_model")

# Convert to TFLite
converter = tf.lite.TFLiteConverter.from_saved_model("saved_model")
tflite_model = converter.convert()

# Save and convert to C array
with open("model.tflite", "wb") as f:
    f.write(tflite_model)

!apt install xxd
!xxd -i model.tflite > model.cc

# Download for Arduino
files.download("model.cc")