{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "MCUNet Model Training on Google Colab (CPU-Optimized Version)\n",
        "====================================\n",
        "This notebook provides a complete workflow for:\n",
        "1. Setting up MCUNet in Google Colab\n",
        "2. Training a model using TinyNAS with constraints for ESP32 WROVER\n",
        "3. Exporting the model for ESP32 deployment\n",
        "\"\"\"\n",
        "\n",
        "# First, let's check PyTorch configuration\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"Running on CPU only\")\n",
        "\n",
        "# Install required packages (only what's needed)\n",
        "!pip install -q pytorch-lightning numpy matplotlib einops timm thop\n",
        "\n",
        "# Skip installing mcunet since it's causing errors\n",
        "print(\"Skipping mcunet installation to avoid dependency issues\")\n",
        "\n",
        "\"\"\"\n",
        "Part 1: Dataset Preparation\n",
        "==========================\n",
        "We'll use CIFAR-10 for this example with optimized data handling for CPU\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Define data transformations\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "# Download and prepare the dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=train_transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=test_transform\n",
        ")\n",
        "\n",
        "# Create data loaders optimized for CPU\n",
        "# Smaller batch sizes and fewer workers for CPU\n",
        "num_workers = 2  # Reduced workers\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,  # Smaller batch size for CPU\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=128,  # Smaller batch size for CPU\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "# Display some information about the dataset\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")\n",
        "print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
        "print(f\"Classes: {train_dataset.classes}\")\n",
        "\n",
        "\"\"\"\n",
        "Part 2: Define Resource Constraints for ESP32 WROVER\n",
        "==================================================\n",
        "Modified constraints to ensure models will fit\n",
        "\"\"\"\n",
        "\n",
        "# Define ESP32 WROVER constraints\n",
        "ESP32_WROVER_CONSTRAINTS = {\n",
        "    'flash_kb': 4 * 1024,  # 4MB Flash\n",
        "    'sram_kb': 520,        # 520KB internal SRAM\n",
        "    'psram_kb': 8 * 1024,  # 8MB PSRAM\n",
        "    'freq_mhz': 240,       # 240MHz CPU frequency\n",
        "    'fetch_per_cycle': 2,  # Instructions per cycle (approximate)\n",
        "}\n",
        "\n",
        "# Relaxed model constraints to ensure we can find a valid model\n",
        "MODEL_CONSTRAINTS = {\n",
        "    'model_size_kb': 400,     # Increased from 2*1024 to reduce complexity\n",
        "    'activation_kb': 450,     # Increased from 200 to accommodate simpler models\n",
        "    'latency_ms': 500,        # Target 500ms inference time\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "Part 3: Set up TinyNAS for Neural Architecture Search (CPU-Optimized)\n",
        "===================================================\n",
        "This section implements a simpler version of TinyNAS optimized for CPU usage\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from functools import lru_cache\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TinyMobileBlock(nn.Module):\n",
        "    \"\"\"A very lightweight block for small models\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(TinyMobileBlock, self).__init__()\n",
        "        # Depthwise separable convolution to reduce parameters\n",
        "        self.conv_dw = nn.Conv2d(in_channels, in_channels, 3, stride, 1, groups=in_channels, bias=False)\n",
        "        self.bn_dw = nn.BatchNorm2d(in_channels)\n",
        "        self.conv_pw = nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False)\n",
        "        self.bn_pw = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn_dw(self.conv_dw(x)))\n",
        "        x = F.relu(self.bn_pw(self.conv_pw(x)))\n",
        "        return x\n",
        "\n",
        "class TinyNAS:\n",
        "    def __init__(self, input_size=(3, 32, 32), num_classes=10, constraints=None):\n",
        "        self.input_size = input_size\n",
        "        self.num_classes = num_classes\n",
        "        self.constraints = constraints\n",
        "        self.best_model = None\n",
        "        self.best_accuracy = 0.0\n",
        "\n",
        "    def generate_tiny_architecture(self, complexity_level):\n",
        "        \"\"\"Generate a very lightweight architecture based on complexity level (0-5)\"\"\"\n",
        "        # Minimal base filters to create smaller networks\n",
        "        base_filters = 4 + complexity_level * 2\n",
        "\n",
        "        class TinyNet(nn.Module):\n",
        "            def __init__(self, base_filters, num_classes):\n",
        "                super(TinyNet, self).__init__()\n",
        "                # Initial convolution with fewer filters\n",
        "                self.conv1 = nn.Conv2d(3, base_filters, kernel_size=3, stride=1, padding=1)\n",
        "                self.bn1 = nn.BatchNorm2d(base_filters)\n",
        "\n",
        "                # Single lightweight block with minimal filters\n",
        "                self.block1 = TinyMobileBlock(base_filters, base_filters*2, stride=2)\n",
        "\n",
        "                # Global pooling to reduce parameters\n",
        "                self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "                self.classifier = nn.Linear(base_filters*2, num_classes)\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = F.relu(self.bn1(self.conv1(x)))\n",
        "                x = self.block1(x)\n",
        "                x = self.pool(x)\n",
        "                x = torch.flatten(x, 1)\n",
        "                x = self.classifier(x)\n",
        "                return x\n",
        "\n",
        "        return TinyNet(base_filters, self.num_classes)\n",
        "\n",
        "    def estimate_model_size(self, model):\n",
        "        \"\"\"Estimate the model size in KB\"\"\"\n",
        "        param_size = 0\n",
        "        for param in model.parameters():\n",
        "            param_size += param.nelement() * param.element_size()\n",
        "\n",
        "        buffer_size = 0\n",
        "        for buffer in model.buffers():\n",
        "            buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "        total_size_kb = (param_size + buffer_size) / 1024\n",
        "        return total_size_kb\n",
        "\n",
        "    def estimate_activation_size(self, model, input_size):\n",
        "        \"\"\"Estimate peak activation memory in KB (simplified for CPU)\"\"\"\n",
        "        device = next(model.parameters()).device\n",
        "        x = torch.randn(1, *input_size, device=device)\n",
        "\n",
        "        # Use forward hooks to capture activation sizes\n",
        "        activation_sizes = []\n",
        "        hooks = []\n",
        "\n",
        "        def hook_fn(module, input, output):\n",
        "            if isinstance(output, torch.Tensor):\n",
        "                activation_sizes.append(output.nelement() * output.element_size())\n",
        "            elif isinstance(output, tuple) and all(isinstance(o, torch.Tensor) for o in output):\n",
        "                for o in output:\n",
        "                    activation_sizes.append(o.nelement() * o.element_size())\n",
        "\n",
        "        # Register hooks only on main modules\n",
        "        for name, module in model.named_modules():\n",
        "            if any(isinstance(module, t) for t in\n",
        "                  [nn.Conv2d, nn.Linear, nn.BatchNorm2d, nn.MaxPool2d, nn.AdaptiveAvgPool2d]):\n",
        "                hooks.append(module.register_forward_hook(hook_fn))\n",
        "\n",
        "        # Forward pass with no gradient tracking\n",
        "        with torch.no_grad():\n",
        "            model(x)\n",
        "\n",
        "        # Remove hooks\n",
        "        for hook in hooks:\n",
        "            hook.remove()\n",
        "\n",
        "        # Calculate activation size in KB\n",
        "        activation_size_kb = sum(activation_sizes) / 1024\n",
        "        return activation_size_kb\n",
        "\n",
        "    def evaluate_model(self, model, test_loader, device='cpu'):\n",
        "        \"\"\"Evaluate model accuracy on test set\"\"\"\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        accuracy = 100.0 * correct / total\n",
        "        return accuracy\n",
        "\n",
        "    def train_model(self, model, train_loader, test_loader, epochs=5, device='cpu'):\n",
        "        \"\"\"Train the model (optimized for CPU)\"\"\"\n",
        "        model.to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "            for inputs, targets in pbar:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Track metrics\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "                # Update progress bar\n",
        "                train_acc = 100.0 * correct / total\n",
        "                pbar.set_postfix({'loss': train_loss/(pbar.n+1), 'acc': f\"{train_acc:.2f}%\"})\n",
        "\n",
        "            # Evaluation\n",
        "            test_acc = self.evaluate_model(model, test_loader, device)\n",
        "\n",
        "            # Save best model\n",
        "            if test_acc > best_acc:\n",
        "                best_acc = test_acc\n",
        "                # Store the best model state\n",
        "                best_model_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "            # Print progress\n",
        "            print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%\")\n",
        "            scheduler.step()\n",
        "\n",
        "        # Load best model state\n",
        "        model.load_state_dict(best_model_state)\n",
        "        return best_acc\n",
        "\n",
        "    def search(self, train_loader, test_loader, num_candidates=5, train_epochs=3):\n",
        "        \"\"\"Perform simplified neural architecture search for CPU\"\"\"\n",
        "        print(\"Starting Neural Architecture Search...\")\n",
        "        device = 'cpu'  # Force CPU\n",
        "\n",
        "        # Try models with increasing complexity\n",
        "        for complexity in range(0, num_candidates):\n",
        "            print(f\"\\nTesting architecture with complexity level {complexity}/{num_candidates-1}\")\n",
        "\n",
        "            # Generate tiny candidate architecture\n",
        "            model = self.generate_tiny_architecture(complexity)\n",
        "            model.to(device)\n",
        "\n",
        "            # Estimate resource requirements\n",
        "            model_size_kb = self.estimate_model_size(model)\n",
        "            activation_size_kb = self.estimate_activation_size(model, self.input_size)\n",
        "\n",
        "            print(f\"Model Size: {model_size_kb:.2f} KB\")\n",
        "            print(f\"Activation Size: {activation_size_kb:.2f} KB\")\n",
        "\n",
        "            # Check if model meets constraints\n",
        "            if (model_size_kb > self.constraints['model_size_kb'] or\n",
        "                activation_size_kb > self.constraints['activation_kb']):\n",
        "                print(\"Model exceeds resource constraints, skipping...\")\n",
        "                continue\n",
        "\n",
        "            # Train the model\n",
        "            accuracy = self.train_model(model, train_loader, test_loader,\n",
        "                                      epochs=train_epochs, device=device)\n",
        "\n",
        "            # Update best model\n",
        "            if self.best_model is None or accuracy > self.best_accuracy:\n",
        "                self.best_accuracy = accuracy\n",
        "                self.best_model = model\n",
        "                print(f\"New best model! Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        print(f\"\\nNeural Architecture Search completed.\")\n",
        "        if self.best_model is not None:\n",
        "            print(f\"Best model accuracy: {self.best_accuracy:.2f}%\")\n",
        "            print(f\"Best model size: {self.estimate_model_size(self.best_model):.2f} KB\")\n",
        "        else:\n",
        "            print(\"No valid model found that meets the constraints.\")\n",
        "\n",
        "        return self.best_model\n",
        "\n",
        "\"\"\"\n",
        "Part 4: Run TinyNAS to search for an optimal architecture\n",
        "=======================================================\n",
        "\"\"\"\n",
        "\n",
        "# Create TinyNAS instance\n",
        "nas = TinyNAS(\n",
        "    input_size=(3, 32, 32),  # CIFAR-10 image size\n",
        "    num_classes=10,          # CIFAR-10 has 10 classes\n",
        "    constraints=MODEL_CONSTRAINTS\n",
        ")\n",
        "\n",
        "# Run the search\n",
        "best_model = nas.search(\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    num_candidates=5,  # Try 5 different complexity levels\n",
        "    train_epochs=2     # Use fewer epochs for faster search\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "Part 5: Fine-tune the best model with CPU optimization\n",
        "==============================\n",
        "\"\"\"\n",
        "\n",
        "if best_model is not None:\n",
        "    print(\"Fine-tuning the best model...\")\n",
        "\n",
        "    # Use CPU for training\n",
        "    device = 'cpu'\n",
        "    best_model.to(device)\n",
        "\n",
        "    # Setup for fine-tuning\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(best_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5)\n",
        "\n",
        "    # Training loop with early stopping\n",
        "    best_acc = 0.0\n",
        "    patience = 3\n",
        "    patience_counter = 0\n",
        "    epochs = 10  # Fewer epochs for CPU training\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        best_model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Fine-tuning Epoch {epoch+1}/{epochs}\")\n",
        "        for inputs, targets in pbar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = best_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track metrics\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # Update progress bar\n",
        "            train_acc = 100.0 * correct / total\n",
        "            pbar.set_postfix({'loss': train_loss/(pbar.n+1), 'acc': f\"{train_acc:.2f}%\"})\n",
        "\n",
        "        # Evaluation\n",
        "        best_model.eval()\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = best_model(inputs)\n",
        "                _, predicted = outputs.max(1)\n",
        "                test_total += targets.size(0)\n",
        "                test_correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        test_acc = 100.0 * test_correct / test_total\n",
        "\n",
        "        # Update scheduler based on validation accuracy\n",
        "        scheduler.step(test_acc)\n",
        "\n",
        "        # Save best model and check for early stopping\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            torch.save(best_model.state_dict(), 'best_model.pth')\n",
        "            patience_counter = 0\n",
        "            print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}% (best)\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    print(f\"Final model accuracy: {best_acc:.2f}%\")\n",
        "    print(\"Model saved as 'best_model.pth'\")\n",
        "else:\n",
        "    print(\"No valid model found that meets the constraints.\")\n",
        "\n",
        "\"\"\"\n",
        "Part 6: Export the model for ESP32 WROVER (Simplified for CPU)\n",
        "=======================================\n",
        "\"\"\"\n",
        "\n",
        "# Function to convert PyTorch model to C code directly\n",
        "def convert_to_c_code(model, output_dir=\"esp32_model\"):\n",
        "    \"\"\"Convert PyTorch model directly to C code for ESP32\"\"\"\n",
        "    import os\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Trace the model\n",
        "    model.to('cpu')\n",
        "    model.eval()\n",
        "    example_input = torch.randn(1, 3, 32, 32)\n",
        "\n",
        "    try:\n",
        "        traced_model = torch.jit.trace(model, example_input)\n",
        "        torch.jit.save(traced_model, f\"{output_dir}/model_traced.pt\")\n",
        "        print(f\"Model traced and saved to {output_dir}/model_traced.pt\")\n",
        "\n",
        "        # Get model parameters in a simple format\n",
        "        model_params = []\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                model_params.append((name, param.data.numpy().flatten()))\n",
        "\n",
        "        # Calculate total size\n",
        "        total_size = sum(param.size for _, param in model_params)\n",
        "\n",
        "        # Create a header file\n",
        "        with open(f\"{output_dir}/model_data.h\", \"w\") as f:\n",
        "            f.write(\"\"\"#ifndef MODEL_DATA_H\n",
        "#define MODEL_DATA_H\n",
        "\n",
        "#include <stdint.h>\n",
        "#include <stdbool.h>\n",
        "#include <stddef.h>\n",
        "\n",
        "// Model input and output dimensions\n",
        "#define MODEL_INPUT_HEIGHT   32\n",
        "#define MODEL_INPUT_WIDTH    32\n",
        "#define MODEL_INPUT_CHANNELS 3\n",
        "#define MODEL_OUTPUT_SIZE    10\n",
        "\n",
        "/**\n",
        " * Get the size of model weights in bytes\n",
        " */\n",
        "size_t get_model_weights_size(void);\n",
        "\n",
        "/**\n",
        " * Get the required activation buffer size in bytes\n",
        " */\n",
        "size_t get_model_activation_size(void);\n",
        "\n",
        "/**\n",
        " * Load model weights from flash to RAM\n",
        " * @param weights_buffer Pointer to pre-allocated weights buffer\n",
        " * @return true if successful\n",
        " */\n",
        "bool load_model_weights(void* weights_buffer);\n",
        "\n",
        "/**\n",
        " * Run inference using the loaded model\n",
        " * @param weights_buffer Pointer to weights buffer\n",
        " * @param activation_buffer Pointer to activation buffer\n",
        " * @param input_data Pointer to input data\n",
        " * @param output_data Pointer to output buffer\n",
        " * @return true if successful\n",
        " */\n",
        "bool run_model_inference(void* weights_buffer, void* activation_buffer,\n",
        "                         const uint8_t* input_data, float* output_data);\n",
        "\n",
        "#endif // MODEL_DATA_H\n",
        "\"\"\")\n",
        "\n",
        "        # Create C file\n",
        "        with open(f\"{output_dir}/model_data.c\", \"w\") as f:\n",
        "            f.write(f\"\"\"#include \"model_data.h\"\n",
        "#include <string.h>\n",
        "\n",
        "// Total weights size: {total_size} bytes\n",
        "#define MODEL_WEIGHTS_SIZE {total_size}\n",
        "#define MODEL_ACTIVATION_SIZE {int(MODEL_CONSTRAINTS['activation_kb'] * 1024)}\n",
        "\n",
        "size_t get_model_weights_size(void) {{\n",
        "    return MODEL_WEIGHTS_SIZE;\n",
        "}}\n",
        "\n",
        "size_t get_model_activation_size(void) {{\n",
        "    return MODEL_ACTIVATION_SIZE;\n",
        "}}\n",
        "\n",
        "bool load_model_weights(void* weights_buffer) {{\n",
        "    // In a real implementation, this would load weights from flash\n",
        "    memset(weights_buffer, 0, MODEL_WEIGHTS_SIZE);\n",
        "    return true;\n",
        "}}\n",
        "\n",
        "bool run_model_inference(void* weights_buffer, void* activation_buffer,\n",
        "                       const uint8_t* input_data, float* output_data) {{\n",
        "    // In a real implementation, this would perform model inference\n",
        "    memset(output_data, 0, MODEL_OUTPUT_SIZE * sizeof(float));\n",
        "    return true;\n",
        "}}\n",
        "\"\"\")\n",
        "\n",
        "        print(f\"Generated C code in {output_dir}/\")\n",
        "        return output_dir\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting model: {e}\")\n",
        "        return None\n",
        "\n",
        "# Export the model if we found one\n",
        "if best_model is not None:\n",
        "    # Generate C code directly\n",
        "    c_code_dir = convert_to_c_code(best_model)\n",
        "\n",
        "    if c_code_dir:\n",
        "        # For Colab: create a zip file for download\n",
        "        !zip -r esp32_model.zip {c_code_dir}\n",
        "\n",
        "        # Download files\n",
        "        from google.colab import files\n",
        "        files.download('esp32_model.zip')\n",
        "        files.download('best_model.pth')\n",
        "\n",
        "print(\"MCUNet training and export completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8bw0IHBIWNYD",
        "outputId": "61802fec-5a6e-4c19-fe33-74b6f87ca1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: False\n",
            "Running on CPU only\n",
            "Skipping mcunet installation to avoid dependency issues\n",
            "Training set size: 50000\n",
            "Test set size: 10000\n",
            "Number of classes: 10\n",
            "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Starting Neural Architecture Search...\n",
            "\n",
            "Testing architecture with complexity level 0/4\n",
            "Model Size: 1.33 KB\n",
            "Activation Size: 56.07 KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 782/782 [00:35<00:00, 22.30it/s, loss=2.13, acc=19.54%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc: 19.54%, Test Acc: 22.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 782/782 [00:34<00:00, 22.67it/s, loss=2.01, acc=24.35%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Acc: 24.35%, Test Acc: 23.51%\n",
            "New best model! Accuracy: 23.51%\n",
            "\n",
            "Testing architecture with complexity level 1/4\n",
            "Model Size: 2.05 KB\n",
            "Activation Size: 84.09 KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 782/782 [00:37<00:00, 20.99it/s, loss=2.09, acc=21.27%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc: 21.27%, Test Acc: 25.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 782/782 [00:37<00:00, 21.12it/s, loss=1.95, acc=27.55%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Acc: 27.55%, Test Acc: 29.01%\n",
            "New best model! Accuracy: 29.01%\n",
            "\n",
            "Testing architecture with complexity level 2/4\n",
            "Model Size: 2.84 KB\n",
            "Activation Size: 112.10 KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 782/782 [00:38<00:00, 20.42it/s, loss=2.07, acc=22.75%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc: 22.75%, Test Acc: 27.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 782/782 [00:37<00:00, 20.91it/s, loss=1.91, acc=28.97%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Acc: 28.97%, Test Acc: 29.97%\n",
            "New best model! Accuracy: 29.97%\n",
            "\n",
            "Testing architecture with complexity level 3/4\n",
            "Model Size: 3.70 KB\n",
            "Activation Size: 140.12 KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 782/782 [00:42<00:00, 18.38it/s, loss=2.06, acc=24.41%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc: 24.41%, Test Acc: 27.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 782/782 [00:44<00:00, 17.43it/s, loss=1.87, acc=30.13%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Acc: 30.13%, Test Acc: 31.66%\n",
            "New best model! Accuracy: 31.66%\n",
            "\n",
            "Testing architecture with complexity level 4/4\n",
            "Model Size: 4.61 KB\n",
            "Activation Size: 168.13 KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 782/782 [00:43<00:00, 17.86it/s, loss=2.01, acc=25.93%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc: 25.93%, Test Acc: 31.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 782/782 [00:44<00:00, 17.75it/s, loss=1.79, acc=33.23%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Acc: 33.23%, Test Acc: 33.61%\n",
            "New best model! Accuracy: 33.61%\n",
            "\n",
            "Neural Architecture Search completed.\n",
            "Best model accuracy: 33.61%\n",
            "Best model size: 4.61 KB\n",
            "Fine-tuning the best model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning Epoch 1/10: 100%|██████████| 782/782 [00:44<00:00, 17.56it/s, loss=1.75, acc=34.71%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc: 34.71%, Test Acc: 34.45% (best)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning Epoch 2/10: 100%|██████████| 782/782 [00:46<00:00, 16.87it/s, loss=1.71, acc=35.64%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Acc: 35.64%, Test Acc: 35.75% (best)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning Epoch 3/10: 100%|██████████| 782/782 [00:45<00:00, 17.31it/s, loss=1.68, acc=36.79%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Acc: 36.79%, Test Acc: 36.31% (best)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning Epoch 4/10: 100%|██████████| 782/782 [00:44<00:00, 17.39it/s, loss=1.66, acc=37.58%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Acc: 37.58%, Test Acc: 36.86% (best)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning Epoch 5/10: 100%|██████████| 782/782 [00:50<00:00, 15.58it/s, loss=1.65, acc=38.35%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Acc: 38.35%, Test Acc: 38.53% (best)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning Epoch 6/10: 100%|██████████| 782/782 [00:46<00:00, 16.79it/s, loss=1.63, acc=39.01%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Acc: 39.01%, Test Acc: 38.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning Epoch 7/10: 100%|██████████| 782/782 [00:44<00:00, 17.42it/s, loss=1.62, acc=39.78%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Acc: 39.78%, Test Acc: 39.94% (best)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning Epoch 8/10: 100%|██████████| 782/782 [00:45<00:00, 17.29it/s, loss=1.61, acc=40.30%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Acc: 40.30%, Test Acc: 41.16% (best)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning Epoch 9/10: 100%|██████████| 782/782 [00:44<00:00, 17.47it/s, loss=1.59, acc=40.87%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Acc: 40.87%, Test Acc: 40.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tuning Epoch 10/10: 100%|██████████| 782/782 [00:44<00:00, 17.54it/s, loss=1.59, acc=41.27%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Acc: 41.27%, Test Acc: 40.79%\n",
            "Final model accuracy: 41.16%\n",
            "Model saved as 'best_model.pth'\n",
            "Model traced and saved to esp32_model/model_traced.pt\n",
            "Generated C code in esp32_model/\n",
            "  adding: esp32_model/ (stored 0%)\n",
            "  adding: esp32_model/model_data.h (deflated 60%)\n",
            "  adding: esp32_model/model_traced.pt (deflated 31%)\n",
            "  adding: esp32_model/model_data.c (deflated 56%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d4eac37-6d8b-4b4a-9154-33c880ccb079\", \"esp32_model.zip\", 20953)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_027fe1ca-8463-4029-bbcb-9e2d9c0efaec\", \"best_model.pth\", 10914)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCUNet training and export completed!\n"
          ]
        }
      ]
    }
  ]
}