# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v20yiiI5Ip1JZNKEC92adJMQ1pgDgMXN
"""

# Commented out IPython magic to ensure Python compatibility.
# MCUNet Training with TinyNAS in Google Colab
# For ESP32 WROVER Target

# First, install dependencies and clone the repository
!pip install torch torchvision tqdm pillow matplotlib opencv-python tensorflow tensorboard

# Clone the MCUNet repository
!git clone https://github.com/mit-han-lab/mcunet.git
# %cd mcunet

# Install MCUNet-specific requirements
!pip install -r requirements.txt

# Import necessary libraries
import os
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, random_split
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import time
import json
from tqdm import tqdm

# Set random seed for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# Define the ESP32 WROVER constraints
ESP32_WROVER_CONSTRAINTS = {
    'flash_size_kb': 4 * 1024,  # 4MB Flash
    'sram_size_kb': 520,  # 520KB internal SRAM
    'psram_size_kb': 8 * 1024,  # 8MB PSRAM
    'frequency_mhz': 240,  # 240MHz CPU
    'max_model_size_kb': 3 * 1024,  # We'll use up to 3MB for model weights
    'max_activation_size_kb': 400,  # Maximum activation memory
}

print("ESP32 WROVER Constraints:", ESP32_WROVER_CONSTRAINTS)

# Create directory for saving models
os.makedirs('models', exist_ok=True)

# ------------------ DATASET PREPARATION ------------------

# Function to download and prepare CIFAR-10 dataset (or your custom dataset)
def prepare_dataset(dataset_name='cifar10', batch_size=64, img_size=32):
    print(f"Preparing {dataset_name} dataset...")

    # Define transformations
    if img_size != 32:
        transform_train = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.RandomCrop(img_size, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ])

        transform_test = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ])
    else:
        transform_train = transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ])

        transform_test = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
        ])

    # Load dataset
    if dataset_name.lower() == 'cifar10':
        trainset = torchvision.datasets.CIFAR10(
            root='./data', train=True, download=True, transform=transform_train)
        testset = torchvision.datasets.CIFAR10(
            root='./data', train=False, download=True, transform=transform_test)
        num_classes = 10

    elif dataset_name.lower() == 'cifar100':
        trainset = torchvision.datasets.CIFAR100(
            root='./data', train=True, download=True, transform=transform_train)
        testset = torchvision.datasets.CIFAR100(
            root='./data', train=False, download=True, transform=transform_test)
        num_classes = 100

    else:
        raise ValueError(f"Dataset {dataset_name} not supported")

    # Create data loaders
    trainloader = DataLoader(
        trainset, batch_size=batch_size, shuffle=True, num_workers=2)
    testloader = DataLoader(
        testset, batch_size=batch_size, shuffle=False, num_workers=2)

    print(f"Dataset prepared with {len(trainset)} training samples and {len(testset)} test samples")
    print(f"Number of classes: {num_classes}")
    return trainloader, testloader, num_classes

# ------------------ TINYNAS SEARCH SPACE ------------------

# Define a base block for the TinyNAS search space
class MBConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio, se_ratio=None):
        super(MBConvBlock, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.stride = stride
        self.expand_ratio = expand_ratio
        self.se_ratio = se_ratio

        # Expansion phase
        expanded_channels = in_channels * expand_ratio
        if expand_ratio != 1:
            self.expand_conv = nn.Sequential(
                nn.Conv2d(in_channels, expanded_channels, kernel_size=1, bias=False),
                nn.BatchNorm2d(expanded_channels),
                nn.ReLU6(inplace=True)
            )

        # Depthwise convolution
        self.depthwise_conv = nn.Sequential(
            nn.Conv2d(expanded_channels, expanded_channels, kernel_size=kernel_size,
                      stride=stride, padding=kernel_size//2, groups=expanded_channels, bias=False),
            nn.BatchNorm2d(expanded_channels),
            nn.ReLU6(inplace=True)
        )

        # Squeeze and Excitation layer
        if se_ratio is not None:
            se_channels = max(1, int(in_channels * se_ratio))
            self.se = nn.Sequential(
                nn.AdaptiveAvgPool2d(1),
                nn.Conv2d(expanded_channels, se_channels, kernel_size=1),
                nn.ReLU6(inplace=True),
                nn.Conv2d(se_channels, expanded_channels, kernel_size=1),
                nn.Sigmoid()
            )
        else:
            self.se = None

        # Pointwise convolution
        self.project_conv = nn.Sequential(
            nn.Conv2d(expanded_channels, out_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels)
        )

        # Skip connection if input and output have the same shape
        self.use_skip_connection = (stride == 1 and in_channels == out_channels)

    def forward(self, x):
        identity = x

        # Expansion
        if self.expand_ratio != 1:
            x = self.expand_conv(x)

        # Depthwise
        x = self.depthwise_conv(x)

        # Squeeze and Excitation
        if self.se is not None:
            x = x * self.se(x)

        # Pointwise
        x = self.project_conv(x)

        # Skip connection
        if self.use_skip_connection:
            x = x + identity

        return x

# TinyNAS Model
class TinyNASModel(nn.Module):
    def __init__(self, input_size=32, num_classes=10, width_mult=1.0):
        super(TinyNASModel, self).__init__()

        # Starting channels - can be adjusted during search
        input_channel = int(32 * width_mult)

        # First layer
        self.features = [
            nn.Sequential(
                nn.Conv2d(3, input_channel, kernel_size=3, stride=2, padding=1, bias=False),
                nn.BatchNorm2d(input_channel),
                nn.ReLU6(inplace=True)
            )
        ]

        # Building MBConv blocks
        # Settings for the bottleneck blocks:
        # [expand_ratio, channels, num_blocks, stride, kernel_size]
        mb_config = [
            [1, 16, 1, 1, 3],
            [6, 24, 2, 2, 3],
            [6, 32, 3, 2, 3],
            [6, 64, 4, 2, 3],
            [6, 96, 3, 1, 3],
            [6, 160, 3, 2, 3],
            [6, 320, 1, 1, 3],
        ]

        # Building blocks based on config
        for t, c, n, s, k in mb_config:
            output_channel = int(c * width_mult)
            for i in range(n):
                stride = s if i == 0 else 1
                self.features.append(
                    MBConvBlock(
                        in_channels=input_channel,
                        out_channels=output_channel,
                        kernel_size=k,
                        stride=stride,
                        expand_ratio=t
                    )
                )
                input_channel = output_channel

        # Last layer before classifier
        last_channel = int(1280 * width_mult) if width_mult > 1.0 else 1280
        self.features.append(
            nn.Sequential(
                nn.Conv2d(input_channel, last_channel, kernel_size=1, bias=False),
                nn.BatchNorm2d(last_channel),
                nn.ReLU6(inplace=True)
            )
        )

        self.features = nn.Sequential(*self.features)

        # Classifier
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Dropout(0.2),
            nn.Linear(last_channel, num_classes)
        )

        # Calculate model size
        self._calculate_model_size()

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

    def _calculate_model_size(self):
        # Estimate model size in KB
        param_size = 0
        for param in self.parameters():
            param_size += param.nelement() * param.element_size()

        buffer_size = 0
        for buffer in self.buffers():
            buffer_size += buffer.nelement() * buffer.element_size()

        self.model_size_kb = (param_size + buffer_size) / 1024

        # Calculate activation memory
        # This is an approximation - would need forward hooks for exact calculation
        self.activation_size_kb = 200  # Placeholder - would need to be measured during forward pass

        return self.model_size_kb, self.activation_size_kb

# Function to train the model
def train_model(model, trainloader, testloader, num_epochs=100, lr=0.01, device='cuda'):
    print(f"Training model on {device}...")
    model = model.to(device)

    # Loss and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)

    # Training loop
    best_acc = 0.0
    training_stats = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}

    for epoch in range(num_epochs):
        # Training
        model.train()
        train_loss = 0.0
        correct = 0
        total = 0

        progress_bar = tqdm(trainloader, desc=f'Epoch {epoch+1}/{num_epochs}')
        for inputs, targets in progress_bar:
            inputs, targets = inputs.to(device), targets.to(device)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward + backward + optimize
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

            # Statistics
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

            progress_bar.set_postfix({
                'loss': train_loss/(progress_bar.n+1),
                'acc': 100.*correct/total
            })

        train_acc = 100. * correct / total
        training_stats['train_loss'].append(train_loss/len(trainloader))
        training_stats['train_acc'].append(train_acc)

        # Evaluation
        model.eval()
        test_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, targets in testloader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, targets)

                test_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()

        test_acc = 100. * correct / total
        training_stats['test_loss'].append(test_loss/len(testloader))
        training_stats['test_acc'].append(test_acc)

        print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss/len(trainloader):.4f}, Train Acc: {train_acc:.2f}%, '
              f'Test Loss: {test_loss/len(testloader):.4f}, Test Acc: {test_acc:.2f}%')

        # Save checkpoint if better
        if test_acc > best_acc:
            best_acc = test_acc
            print(f'New best accuracy: {best_acc:.2f}%. Saving model...')
            torch.save(model.state_dict(), 'models/best_model.pth')

        # Update learning rate
        scheduler.step()

    print(f'Training complete. Best accuracy: {best_acc:.2f}%')
    return model, training_stats, best_acc

# ------------------ TINYNAS SEARCH ------------------

def tinynas_search(trainloader, testloader, num_classes, constraints, num_candidates=5, epochs_per_candidate=10):
    """
    Simplified TinyNAS search algorithm
    """
    print("Starting TinyNAS search...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")

    # Define the search space for width multipliers and input sizes
    width_mults = [0.35, 0.5, 0.75, 1.0]
    input_sizes = [32, 64, 96, 128]

    # Store results
    search_results = []

    for width_mult in width_mults:
        for input_size in input_sizes:
            # Create model with current config
            model = TinyNASModel(input_size=input_size, num_classes=num_classes, width_mult=width_mult)

            # Check if model meets size constraints
            model_size_kb, activation_size_kb = model._calculate_model_size()

            if model_size_kb > constraints['max_model_size_kb'] or activation_size_kb > constraints['max_activation_size_kb']:
                print(f"Skipping model with width={width_mult}, input_size={input_size} "
                      f"(model_size={model_size_kb:.2f}KB, activation_size={activation_size_kb:.2f}KB) - exceeds constraints")
                continue

            print(f"\nEvaluating model with width={width_mult}, input_size={input_size}")
            print(f"Estimated model size: {model_size_kb:.2f}KB, activation size: {activation_size_kb:.2f}KB")

            # Train model for fewer epochs during search
            _, _, accuracy = train_model(
                model, trainloader, testloader,
                num_epochs=epochs_per_candidate,
                device=device
            )

            # Record results
            search_results.append({
                'width_mult': width_mult,
                'input_size': input_size,
                'model_size_kb': model_size_kb,
                'activation_size_kb': activation_size_kb,
                'accuracy': accuracy
            })

            # Save results after each model
            with open('models/search_results.json', 'w') as f:
                json.dump(search_results, f, indent=4)

    # Find the best model configurations
    search_results.sort(key=lambda x: x['accuracy'], reverse=True)
    print("\nSearch complete. Top models:")
    for i, result in enumerate(search_results[:num_candidates]):
        print(f"{i+1}. width={result['width_mult']}, input_size={result['input_size']}, "
              f"acc={result['accuracy']:.2f}%, model_size={result['model_size_kb']:.2f}KB")

    # Return the best configuration
    best_config = search_results[0]
    print(f"\nBest model configuration: width={best_config['width_mult']}, input_size={best_config['input_size']}")
    return best_config

# ------------------ MODEL CONVERSION ------------------

def convert_to_tflite(model, input_size):
    """
    Convert PyTorch model to TFLite format
    """
    print("Converting PyTorch model to TFLite format...")

    # Create example input
    dummy_input = torch.randn(1, 3, input_size, input_size)

    # Export to ONNX
    onnx_path = 'models/model.onnx'
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={'input': {0: 'batch_size'},
                      'output': {0: 'batch_size'}}
    )
    print(f"ONNX model saved to {onnx_path}")

    # Convert ONNX to TFLite
    import onnx
    from onnx_tf.backend import prepare
    import tensorflow as tf

    # Load ONNX model
    onnx_model = onnx.load(onnx_path)

    # Convert ONNX to TensorFlow
    tf_rep = prepare(onnx_model)

    # Create a TensorFlow SavedModel
    tf_model_path = 'models/tf_model'
    tf_rep.export_graph(tf_model_path)

    # Convert SavedModel to TFLite
    converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)

    # Enable optimizations
    converter.optimizations = [tf.lite.Optimize.DEFAULT]

    # Apply quantization for smaller model size
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8

    # Generate representative dataset for quantization
    def representative_dataset():
        for data, _ in testloader:
            yield [data[0:1].numpy()]

    converter.representative_dataset = representative_dataset

    # Convert the model
    tflite_model = converter.convert()

    # Save the TFLite model
    tflite_path = 'models/model.tflite'
    with open(tflite_path, 'wb') as f:
        f.write(tflite_model)

    print(f"TFLite model saved to {tflite_path}")
    return tflite_path

# ------------------ C CODE GENERATION ------------------

def generate_c_code(tflite_path, output_dir='models/esp32'):
    """
    Generate C code from TFLite model for ESP32
    """
    print("Generating C code for ESP32...")

    # Create output directory
    os.makedirs(output_dir, exist_ok=True)

    # Read TFLite model
    with open(tflite_path, 'rb') as f:
        tflite_model = f.read()

    # Convert model to C array
    c_array = ','.join([f'0x{byte:02x}' for byte in tflite_model])

    # Generate header file
    header_content = f"""#ifndef MODEL_DATA_H
#define MODEL_DATA_H

#include <stdint.h>
#include <stdbool.h>
#include <stddef.h>

// Model parameters
#define MODEL_SIZE {len(tflite_model)}
#define MODEL_INPUT_SIZE {input_size}
#define MODEL_NUM_CLASSES {num_classes}

// Function declarations
void init_model(void);
bool run_inference(const uint8_t* input, uint8_t* output);
void deinit_model(void);

#endif // MODEL_DATA_H
"""

    # Generate C file
    c_content = f"""#include "model_data.h"
#include "tensorflow/lite/micro/all_ops_resolver.h"
#include "tensorflow/lite/micro/micro_error_reporter.h"
#include "tensorflow/lite/micro/micro_interpreter.h"
#include "tensorflow/lite/schema/schema_generated.h"
#include "tensorflow/lite/version.h"
#include "esp_log.h"
#include "esp_heap_caps.h"

// TFLite model data
const unsigned char model_data[] = {{{c_array}}};

// TFLite globals
namespace {{
tflite::ErrorReporter* error_reporter = nullptr;
const tflite::Model* model = nullptr;
tflite::MicroInterpreter* interpreter = nullptr;
TfLiteTensor* input = nullptr;
TfLiteTensor* output = nullptr;

// Create an area of memory to use for input, output, and intermediate arrays
constexpr int kTensorArenaSize = {int(ESP32_WROVER_CONSTRAINTS['max_activation_size_kb'] * 1024)};
static uint8_t* tensor_arena;
}}

void init_model(void) {{
    // Set up logging
    static tflite::MicroErrorReporter micro_error_reporter;
    error_reporter = &micro_error_reporter;

    // Map the model into a usable data structure
    model = tflite::GetModel(model_data);

    // Check version
    if (model->version() != TFLITE_SCHEMA_VERSION) {{
        TF_LITE_REPORT_ERROR(error_reporter,
                             "Model schema version %d not equal to supported version %d.",
                             model->version(), TFLITE_SCHEMA_VERSION);
        return;
    }}

    // Allocate memory for tensor arena
    tensor_arena = (uint8_t*)heap_caps_malloc(kTensorArenaSize, MALLOC_CAP_8BIT | MALLOC_CAP_INTERNAL);
    if (tensor_arena == nullptr) {{
        TF_LITE_REPORT_ERROR(error_reporter, "Failed to allocate tensor arena");
        return;
    }}

    // Pull in all the operation implementations needed
    static tflite::AllOpsResolver resolver;

    // Build an interpreter to run the model
    static tflite::MicroInterpreter static_interpreter(model, resolver, tensor_arena,
                                                      kTensorArenaSize, error_reporter);
    interpreter = &static_interpreter;

    // Allocate memory from the tensor_arena for the model's tensors
    TfLiteStatus allocate_status = interpreter->AllocateTensors();
    if (allocate_status != kTfLiteOk) {{
        TF_LITE_REPORT_ERROR(error_reporter, "AllocateTensors() failed");
        return;
    }}

    // Get pointers to the model's input and output tensors
    input = interpreter->input(0);
    output = interpreter->output(0);
}}

bool run_inference(const uint8_t* input_data, uint8_t* output_data) {{
    // Copy input data
    for (int i = 0; i < MODEL_INPUT_SIZE * MODEL_INPUT_SIZE * 3; ++i) {{
        input->data.int8[i] = input_data[i] - 128;  // Convert to int8 format
    }}

    // Run inference
    TfLiteStatus invoke_status = interpreter->Invoke();
    if (invoke_status != kTfLiteOk) {{
        TF_LITE_REPORT_ERROR(error_reporter, "Invoke failed");
        return false;
    }}

    // Copy output
    for (int i = 0; i < MODEL_NUM_CLASSES; ++i) {{
        output_data[i] = output->data.int8[i] + 128;  // Convert back to uint8
    }}

    return true;
}}

void deinit_model(void) {{
    // Free memory
    heap_caps_free(tensor_arena);
}}
"""

    # Write files
    with open(f'{output_dir}/model_data.h', 'w') as f:
        f.write(header_content)

    with open(f'{output_dir}/model_data.c', 'w') as f:
        f.write(c_content)

    print(f"C code generated in {output_dir}")
    return output_dir

# ------------------ MAIN EXECUTION ------------------

# Set parameters
dataset_name = 'cifar10'
batch_size = 64
img_size = 96  # Adjust based on your needs
num_epochs = 100

# Check for GPU
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Using device: {device}")

# Prepare dataset
trainloader, testloader, num_classes = prepare_dataset(
    dataset_name=dataset_name,
    batch_size=batch_size,
    img_size=img_size
)

# Perform TinyNAS search to find the best architecture
best_config = tinynas_search(
    trainloader,
    testloader,
    num_classes,
    ESP32_WROVER_CONSTRAINTS,
    num_candidates=5,
    epochs_per_candidate=5  # Use a small number for quick search
)

# Train the best model with full epochs
print("\nTraining best model configuration with full epochs...")
best_model = TinyNASModel(
    input_size=best_config['input_size'],
    num_classes=num_classes,
    width_mult=best_config['width_mult']
)

# Save input size for later use in code generation
input_size = best_config['input_size']

# Full training
final_model, training_stats, final_accuracy = train_model(
    best_model,
    trainloader,
    testloader,
    num_epochs=num_epochs,
    device=device
)

print(f"Final model accuracy: {final_accuracy:.2f}%")

# Plot training results
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(training_stats['train_loss'], label='Train Loss')
plt.plot(training_stats['test_loss'], label='Test Loss')
plt.title('Loss Curves')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(training_stats['train_acc'], label='Train Accuracy')
plt.plot(training_stats['test_acc'], label='Test Accuracy')
plt.title('Accuracy Curves')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.tight_layout()
plt.savefig('models/training_curves.png')
plt.show()

# Convert model to TFLite format
tflite_path = convert_to_tflite(final_model, input_size)

# Generate C code for ESP32
esp32_code_dir = generate_c_code(tflite_path)

# Create a zip file of the ESP32 code
!zip -r models/esp32_model.zip {esp32_code_dir}

# Download the generated files
from google.colab import files
files.download('models/esp32_model.zip')
files.download('models/model.tflite')
files.download('models/best_model.pth')
files.download('models/training_curves.png')

print("Complete! Your model has been trained, converted, and is ready for deployment on ESP32 WROVER.")
print("Please integrate the generated model_data.c and model_data.h into your ESP-IDF project.")